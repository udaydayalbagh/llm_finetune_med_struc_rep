# CONFIGURATION FILE

# Algorithm
algorithm: "sft"

# Model settings
model_checkpoint: "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
local_model_dir: ""
max_seq_length: 6000           # Can increase for longer reasoning traces
lora_rank: 32                  # Larger rank = smarter, but slower
load_in_4bit: True             # False for LoRA 16bit
load_in_8bit: False
fast_inference: False          # Enable vLLM fast inference
gpu_memory_utilization: 0.9    # Reduce if out of memory

# Data settings
dataset_name: "FreedomIntelligence/medical-o1-reasoning-SFT"   # Huggingface dataset name for SFT

# System prompt for the LLM
system_prompt: "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. Please answer the following medical question."
include_think_tag: True  # If True, the prompt will include think tags.

# Training settings
random_state: 3407
target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]    # Remove QKVO if out of memory
learning_rate: 1e-4
weight_decay: 0.1
lr_scheduler_type: "linear"
optim: "adamw_8bit"
logging_steps: 10
per_device_train_batch_size: 2
gradient_accumulation_steps: 4  # Increase to 4 for smoother training
warmup_steps: 5
num_train_epochs: 1  # Set to 1 for a full training run
max_steps: -1
save_steps: 1000
save_total_limit: 2
max_grad_norm: 0.01
output_dir: "llms/DeepSeek-R1-Distill-Llama-8B-SFT"

# Checkpoint settings
checkpoint_dir: "llms/DeepSeek-R1-Distill-Llama-8B-SFT"

# Logs settings:
logs_dir: "logs"
logs_file_name: "DeepSeek-R1-Distill-Llama-8B-SFT-Training-Logs.json"

